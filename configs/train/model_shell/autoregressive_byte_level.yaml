shell_type: "autoregressive_byte_encoding"
tokenizer: "bpe"
vocab_size: 257
embedding_dim: 256
pooling_tokenizer: "gpt2"
pooling_vocab_size: 50304
tokenizer_dataset_name: "simple_en_wiki"
context_window: 512
