wandb_version: 1

general:
  desc: null
  value:
    logging:
      wandb_log: true
      wandb_project: TinyUniverse
    paths:
      output_dir: outputs
      data_path: data
      checkpoint_dir: checkpoints
    seed: 489
    device: cuda
model:
  desc: null
  value:
    model: baseline
    tokenizer: gpt2
    context_window: 512
    vocab_size: 50256
    depth: 6
    hidden_dim: 64
    num_heads: 8
    ffn_dim: 256
    dropout: 0.0
    bias: false
trainer:
  desc: null
  value:
    dataset: debug
    training:
      batch_size: 24
      gradient_accumulation_steps: 20
      max_iters: 1000
      lr_decay_iters: 1000
      warmup_iters: 10
      eval_interval: 500
      log_interval: 1
      eval_iters: 200
    optimizer:
      name: nanoGPTadamW
      lr: 0.0006
      min_lr: 6.0e-05
      weight_decay: 0.1
      beta1: 0.9
      beta2: 0.95
      grad_clip: 1.0
      decay_lr: true
      warmup_iters: 5000
    scheduler:
      name: cosine
    dataloader:
      name: standard
    loss_fn:
      name: cross_entropy
_wandb:
  desc: null
  value:
    python_version: 3.11.7
    cli_version: 0.16.4
    framework: huggingface
    huggingface_version: 4.37.0.dev0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1712073347.0
    t:
      1:
      - 1
      - 11
      - 49
      - 50
      - 51
      - 55
      2:
      - 1
      - 11
      - 49
      - 50
      - 51
      - 55
      3:
      - 13
      - 16
      - 23
      - 24
      4: 3.11.7
      5: 0.16.4
      6: 4.37.0.dev0
      8:
      - 5
      13: linux-x86_64
