"""
Utils functions and classes for MoE layers.
"""

import torch
from torch import nn
from torch.nn import functional as F


@torch.jit.script
def compute_gating(
    k: int, num_experts: int, top_k_gates: torch.Tensor, top_k_indices: torch.Tensor
):
    """
    Compute gating values for the mixture of experts based on probabilities and top-k indices.
    Taken from: https://github.com/myshell-ai/JetMoE/blob/main/jetmoe/utils/parallel_experts.py
    Args:
        k (int): Number of experts to select.
        num_experts (int): Total number of experts.
        top_k_gates (torch.Tensor): Gating values for top-k experts (batch_size x k).
        top_k_indices (torch.Tensor): Indices of top-k experts (batch_size x k).

    Returns:
        torch.Tensor: Batch-level gating values.
        torch.Tensor: Batch-level expert indices.
        torch.Tensor: Expert size for each expert.
        torch.Tensor: Sorted indices of top-k experts.
    """
    zeros = torch.zeros(
        [top_k_gates.size(0), num_experts],
        dtype=top_k_gates.dtype,
        device=top_k_gates.device,
    )
    gates = zeros.scatter(1, top_k_indices, 1)
    expert_size = gates.long().sum(0)
    top_k_gates = top_k_gates.flatten()
    top_k_experts = top_k_indices.flatten()
    _, index_sorted_experts = top_k_experts.sort(0)
    batch_index = index_sorted_experts.div(k, rounding_mode="trunc")
    batch_gates = top_k_gates[index_sorted_experts]
    return batch_gates, batch_index, expert_size, index_sorted_experts


class ParallelExperts(nn.Module):
    """
    Parallel experts layer.
    """

    def __init__(self, num_experts, input_size, output_size) -> None:
        """
        Initialize the ParallelExperts module.
        Taken from: https://github.com/myshell-ai/JetMoE/blob/main/jetmoe/utils/parallel_experts.py
        Args:
            num_experts (int): Number of experts.
            input_size (int): Size of the input.
            output_size (int): Size of the output.
            bias (bool): Whether to include bias terms.
        """
        super().__init__()
        self.weight = nn.Parameter(torch.empty(num_experts, output_size, input_size))
        self.reset_parameters()
        self.num_experts = num_experts
        self.input_size = input_size
        self.output_size = output_size

    def extra_repr(self):
        return (
            f"num_experts={self.num_experts}, input_size={self.input_size}"
            f", output_size={self.output_size}"
        )

    def reset_parameters(self) -> None:
        """
        Reset the parameters of the model.
        """
        nn.init.uniform_(
            self.weight, -1.0 / self.weight.size(1), 1.0 / self.weight.size(1)
        )

    def forward(self, inputs, expert_size):
        """
        Forward pass of the ParallelExperts module.

        Args:
            inputs (Tensor): Input tensor.
            expert_size: Expert size information.

        Returns:
            Tensor: Output tensor.
        """
        input_list = inputs.split(expert_size, dim=0)
        output_list = []
        for i in range(self.num_experts):
            # pylint: disable=not-callable
            output_list.append(F.linear(input_list[i], self.weight[i]))
            # pylint: enable=not-callable
        results = torch.cat(output_list, dim=0)
        return results
